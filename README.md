
# ğŸ“š arXiv Research Paper Search Engine

> Efficient Academic Paper Discovery with Advanced XML Querying and Document Embeddings

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-Latest-green.svg)](https://fastapi.tiangolo.com/)
[![MySQL](https://img.shields.io/badge/MySQL-8.0+-blue.svg)](https://www.mysql.com/)
[![arXiv API](https://img.shields.io/badge/arXiv-API-orange.svg)](https://arxiv.org/help/api)

**By: Rustom Bhesania & Viresh Kashetti**  
*Text Technology Summer 25*

---

## ğŸ¯ Problem Statement

Current academic research discovery faces several challenges:

- **Time-Intensive Literature Review**
- **Limited Search Capabilities**
- **Lack of Semantic Understanding**
- **No Similarity Analysis**

---

## ğŸ’¡ Proposed Solution

A **local database of arXiv papers** with advanced similarity evaluation using:

- Document Embeddings (e.g., BERT)
- XPath/XQuery-based XML parsing
- Multi-modal Search Capabilities
- FastAPI Interface for Real-Time Semantic Search

---

## ğŸ—ï¸ System Architecture

```mermaid
graph TD
    A[arXiv API] --> B[XML Response]
    B --> C[XPath/XQuery Processing]
    C --> D[MySQL Database]
    D --> E[Abstract Extraction]
    E --> F[Document Embeddings]
    F --> G[Similarity Comparison]
    G --> H[Similar Papers Output]

    I[User Query] --> J[Multi-Modal Search Engine]
    J --> D
    J --> F

    style A fill:#ff9800
    style D fill:#4caf50
    style F fill:#2196f3
    style H fill:#9c27b0
````

---

## ğŸ”„ Workflow

### 1. Data Collection

* arXiv API fetch by category/author/keyword
* XML response with abstract and metadata
* Batch download and XML parsing
* MySQL storage and deduplication

### 2. Data Processing

```
XML â†’ XPath/XQuery â†’ MySQL â†’ BERT Embedding â†’ Semantic Index
```

### 3. Search & Discovery

* Input a reference paper
* Compute embedding
* Compare with database
* Return ranked similar papers

---

## ğŸš€ Key Features

### ğŸ“Œ Core

* Multi-Modal Search
* XML-based structured querying
* Semantic ranking
* Real-time FastAPI access

### ğŸ§  Technical

* Sentence-BERT: all-MiniLM-L6-v2
* Embedding batch processing
* MySQL backend with BLOB storage
* Swagger UI for API testing
* Rate limit aware fetch pipeline

---

## ğŸ› ï¸ Tech Stack

| Component          | Technology                  |
| ------------------ | --------------------------- |
| **Backend**        | FastAPI, Python             |
| **Database**       | MySQL                       |
| **Embeddings**     | Sentence-BERT, Transformers |
| **XML Processing** | XPath, XQuery, lxml         |
| **Infra**          | Docker (optional)           |
| **Data Source**    | arXiv, Semantic Scholar     |

---

## ğŸ“¦ Installation & Setup

### Prerequisites

* Python 3.8+
* MySQL 8.0+
* Docker (optional)
* Git

### Step-by-Step

```bash
# 1. Clone Repo
git clone https://github.com/Viresh26/Text_Technology.git
cd Text_Technology

# 2. Virtual Env
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# 3. Install Deps
pip install -r requirements.txt

# 4. MySQL Setup
mysql -u root -p
CREATE DATABASE arxiv_papers;
CREATE USER 'arxiv_app_user'@'localhost' IDENTIFIED BY 'your_secure_password';
GRANT ALL PRIVILEGES ON arxiv_papers.* TO 'arxiv_app_user'@'localhost';
FLUSH PRIVILEGES;
EXIT;

# 5. Add .env
echo "MYSQL_HOST=localhost
MYSQL_USER=arxiv_app_user
MYSQL_PASSWORD=your_secure_password
MYSQL_DATABASE=arxiv_papers" > .env

# 6. Init Schema
python scripts/init_database.py

# 7. Run Pipeline
python arxiv_pipeline.py

# 8. Start API
uvicorn fastapi_app:app --host 0.0.0.0 --port 8000 --reload
```

---

## ğŸ“¡ API Documentation

Access via: [http://localhost:8000/docs](http://localhost:8000/docs)

### /health (GET)

```json
{
  "status": "ok",
  "model_loaded": true
}
```

### /embed (POST)

```json
{
  "text": "This paper proposes a new algorithm..."
}
```

Returns:

```json
{
  "embedding": [...],
  "model_used": "all-MiniLM-L6-v2"
}
```

### /embed\_batch (POST)

```json
{
  "texts": ["Doc 1 text", "Doc 2 text"]
}
```

Returns:

```json
{
  "embeddings": [[...], [...]],
  "model_used": "all-MiniLM-L6-v2"
}
```

---

## ğŸ§ª Usage Examples

```python
# Search papers
res = requests.get("http://localhost:8000/search", params={
    "query": "machine learning",
    "category": "cs.AI",
    "max_results": 20
})

# Similarity analysis
res = requests.post("http://localhost:8000/similarity", json={
    "reference_paper_id": "2103.00020",
    "similarity_threshold": 0.7
})

# XML Query
res = requests.post("http://localhost:8000/xml-query", json={
    "xpath": "//entry[contains(summary, 'neural network')]",
    "limit": 50
})
```

---

## ğŸ§± Project Structure

```
Text_Technology/
â”œâ”€â”€ main.py               # FastAPI entry point
â”œâ”€â”€ fastapi_app.py        # Embedding API
â”œâ”€â”€ arxiv_pipeline.py     # Ingestion pipeline
â”œâ”€â”€ .env                  # DB credentials
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ init_database.py
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ search.py
â”‚   â”œâ”€â”€ similarity.py
â”‚   â””â”€â”€ xml_query.py
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ arxiv_client.py
â”‚   â”œâ”€â”€ xml_processor.py
â”‚   â”œâ”€â”€ embeddings.py
â”‚   â””â”€â”€ similarity.py
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ models.py
â”‚   â”œâ”€â”€ connection.py
â”‚   â””â”€â”€ repositories.py
â”œâ”€â”€ tests/
â””â”€â”€ README.md
```

---

## ğŸš§ Challenges

| Challenge         | Solution                         |
| ----------------- | -------------------------------- |
| arXiv Rate Limits | Smart batching and delays        |
| Missing Metadata  | Semantic Scholar fallback        |
| Embedding Cost    | Batch processing + caching       |
| Scaling Search    | Indexed similarity (e.g., FAISS) |

---

## ğŸ”® Roadmap

### Phase 1 â€“ Core

* Personalized Paper Recommendations
* Citation Graph / Impact Analysis

### Phase 2 â€“ Productization

* Public API
* Browser Plugin
* Frontend UI (React or Streamlit)

### Phase 3 â€“ Collaboration

* Shared Libraries
* Annotations & Comments
* Research Network Tools

---

## ğŸ§ª Testing

```bash
pytest tests/ -v
pytest tests/ --cov=core --cov-report=html
```

---

## ğŸ¤ Contributing

1. Fork the repo
2. Create a branch: `git checkout -b feature-name`
3. Add your feature + tests
4. Push and open a PR

---

## ğŸ“š References

* [arXiv API Docs](https://info.arxiv.org/help/api/index.html)
* [Sentence-BERT](https://www.sbert.net/)
* [Semantic Scholar API](https://api.semanticscholar.org/)
* Reimers & Gurevych, 2019
* Cer et al., 2018 (USE)

---

## ğŸ“„ License

Licensed under the **MIT License**. See the [LICENSE](LICENSE) file.

---

## ğŸ‘¥ Authors

* **Rustom Bhesania**
* **Viresh Kashetti**

*Text Technology Summer 25*

---

## ğŸ†˜ Support

* [GitHub Issues](https://github.com/Viresh26/Text_Technology/issues)
* [GitHub Repo](https://github.com/Viresh26/Text_Technology)

---

**â­ Found it helpful? Star the repo to show your support!**

```

---

Let me know if you'd like:

- A clean `Dockerfile`
- A `.gitignore` template
- A deployment guide (Heroku, Render, EC2, etc.)
- Or integration with frontend tools like Streamlit or React

I'm happy to help streamline the next phase.
```
